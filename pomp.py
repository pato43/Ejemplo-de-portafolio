import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.datasets import load_iris
import numpy as np

# Configuraci贸n inicial de la p谩gina
st.set_page_config(page_title="Portafolio de Ciencia de Datos - Alexander Eduardo Rojas Garay", layout="wide")

# T铆tulo del Portafolio
st.title("Ejemplo de Portafolio de Ciencia de Datos e Informaci贸n de Curso")
st.markdown("""
### Alexander Eduardo Rojas Garay
Bienvenido a mi portafolio de ciencia de datos. En cada pesta帽a, exploro un modelo de Machine Learning con un conjunto de datos de muestra, explicando su contexto, funcionalidad y aplicaci贸n.
""")

# Informaci贸n del curso
st.sidebar.title("Curso Basico de Python para Ciencia de Datos")
st.sidebar.markdown("""
**Duraci贸n:** 3 meses  
**Costo:** 130 por semana o 400 por el mes completo (1 semana GRATIS) 
**Certificaci贸n:** Constancia de Microsoft al finalizar  
[Registrarse aqu铆](https://forms.office.com/r/Mx65d2dHP9)  
[LinkedIn](https://linkedin.com/in/alexandereduardo)  
""")

# Temario del curso
st.sidebar.subheader("Temario del Curso")
with st.sidebar.expander("M贸dulo 1: Fundamentos de Python"):
    st.write("""
    - Introducci贸n a Python y Google Colab  
    - Estructuras b谩sicas de control y datos en Python  
    - Funciones y estructuras de datos avanzadas  
    """)

with st.sidebar.expander("M贸dulo 2: Manejo de Datos en Python"):
    st.write("""
    - Manipulaci贸n de arrays y operaciones avanzadas con Numpy  
    - Transformaci贸n y limpieza de datos con Pandas  
    """)

with st.sidebar.expander("M贸dulo 3: Estad铆stica y Probabilidad"):
    st.write("""
    - Estad铆stica descriptiva y visualizaci贸n de datos  
    - Conceptos b谩sicos de probabilidad y distribuciones  
    - Inferencia estad铆stica y pruebas de hip贸tesis  
    """)

with st.sidebar.expander("M贸dulo 4: Matem谩ticas para Ciencia de Datos"):
    st.write("""
    - lgebra lineal aplicada a ciencia de datos  
    - C谩lculo para optimizaci贸n y modelos  
    - Matem谩ticas discretas y teor铆a de grafos  
    """)

with st.sidebar.expander("M贸dulo 5: Visualizaci贸n de Datos"):
    st.write("""
    - Gr谩ficos avanzados con Matplotlib y Seaborn  
    - Creaci贸n de reportes interactivos en Google Data Studio (Looker Studio)  
    """)

with st.sidebar.expander("M贸dulo 6: Introducci贸n al Machine Learning"):
    st.write("""
    - Preparaci贸n de datos para modelos de ML  
    - Modelos de clasificaci贸n y regresi贸n b谩sicos  
    - Clustering y reducci贸n de dimensionalidad  
    """)

with st.sidebar.expander("M贸dulo 7: Bases de Datos para Ciencia de Datos"):
    st.write("""
    - Consultas SQL b谩sicas y avanzadas  
    - Conexi贸n y manejo de datos en Python  
    """)

with st.sidebar.expander("M贸dulo 8: Proyecto Final de Ciencia de Datos"):
    st.write("""
    - Definici贸n del problema, modelado y an谩lisis  
    - Presentaci贸n de resultados en Looker Studio  
    """)

# Cargar el dataset de ejemplo
data = load_iris()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

# Divisi贸n de los datos
X = df.drop(columns='target')
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Opciones de la barra lateral
st.sidebar.header("Modelos de Machine Learning")
page = st.sidebar.radio("Selecciona el modelo para ver detalles", 
                        ["Exploraci贸n de Datos", "M谩quina de Vectores de Soporte (SVM)", "K-Nearest Neighbors (KNN)", 
                         "Clustering con KMeans", "Regresi贸n Log铆stica", "rbol de Decisi贸n"])

# Exploraci贸n de datos
if page == "Exploraci贸n de Datos":
    st.header("Exploraci贸n de Datos")
    st.write("Visualizaci贸n general de los datos de muestra (dataset de flores Iris).")
    st.write(df.head())
    
    # Gr谩ficos exploratorios
    st.subheader("Distribuci贸n de Clases")
    fig, ax = plt.subplots()
    sns.violinplot(x='target', data=df, inner='quartile')
    ax.set_xticklabels(data.target_names)
    st.pyplot(fig)
    
    st.subheader("Mapa de Calor de Correlaciones")
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm', ax=ax)
    st.pyplot(fig)

# SVM
elif page == "M谩quina de Vectores de Soporte (SVM)":
    st.header("M谩quina de Vectores de Soporte (SVM)")
    st.write("""
    El modelo SVM es ampliamente utilizado para clasificaci贸n en casos con clases claramente separables. Este modelo busca encontrar un hiperplano 贸ptimo que maximice la separaci贸n entre las clases. Aqu铆 se utiliza para clasificar tipos de flores en el dataset de Iris.
    """)
    svm_model = SVC(kernel='linear')
    svm_model.fit(X_train, y_train)
    y_pred = svm_model.predict(X_test)
    
    # Gr谩fico del hiperplano
    st.write("Visualizaci贸n del Hiperplano:")
    fig, ax = plt.subplots()
    sns.scatterplot(x='sepal length (cm)', y='petal length (cm)', hue='target', data=df, palette='viridis')
    ax.set_title("Separaci贸n de Clases SVM")
    st.pyplot(fig)

# K-Nearest Neighbors (KNN)
elif page == "K-Nearest Neighbors (KNN)":
    st.header("K-Nearest Neighbors (KNN)")
    st.write("""
    El modelo KNN clasifica un nuevo punto bas谩ndose en la clase mayoritaria de sus puntos vecinos m谩s cercanos. Es ideal para problemas donde las clases est谩n bien definidas y funciona bien con conjuntos de datos peque帽os. En este ejemplo, se usa KNN para clasificar tipos de flores en el dataset de Iris.
    """)
    knn_model = KNeighborsClassifier(n_neighbors=5)
    knn_model.fit(X_train, y_train)
    y_pred = knn_model.predict(X_test)
    
    # Gr谩fico de dispersi贸n 3D
    st.write("Gr谩fico de Dispersi贸n 3D de KNN:")
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    ax.scatter(X_test.iloc[:, 0], X_test.iloc[:, 1], X_test.iloc[:, 2], c=y_pred, cmap='cool')
    ax.set_title("Clasificaci贸n con KNN")
    st.pyplot(fig)

# KMeans
elif page == "Clustering con KMeans":
    st.header("Clustering con KMeans")
    st.write("""
    KMeans es un algoritmo de clustering sin supervisi贸n. Agrupa datos en "clusters" o grupos seg煤n su similitud. Es 煤til para segmentaci贸n y descubrimiento de patrones sin etiquetas. En este caso, usamos KMeans para identificar grupos en el dataset de Iris.
    """)
    kmeans = KMeans(n_clusters=3, random_state=42)
    df['kmeans_cluster'] = kmeans.fit_predict(X)
    
    fig, ax = plt.subplots()
    sns.scatterplot(x='sepal length (cm)', y='sepal width (cm)', hue='kmeans_cluster', data=df, palette="viridis", ax=ax)
    st.pyplot(fig)

# Regresi贸n Log铆stica
elif page == "Regresi贸n Log铆stica":
    st.header("Regresi贸n Log铆stica")
    st.write("""
    La regresi贸n log铆stica predice probabilidades de una clase, ideal para clasificaci贸n binaria. Aqu铆 se aplica a la clasificaci贸n de tipos de flores en el dataset de Iris, demostrando su versatilidad en problemas de m煤ltiples clases.
    """)
    log_model = LogisticRegression()
    log_model.fit(X_train, y_train)
    y_pred = log_model.predict(X_test)
    
    # Curva ROC
    st.write("Curva ROC para Regresi贸n Log铆stica:")
    fig, ax = plt.subplots()
    sns.lineplot([0,1], [0,1], linestyle='--', ax=ax)
    # Agrega aqu铆 la l贸gica de ROC si deseas detallar m谩s
    ax.set_title("Curva ROC")
    st.pyplot(fig)

# rbol de Decisi贸n
elif page == "rbol de Decisi贸n":
    st.header("rbol de Decisi贸n")
    st.write("""
    Los 谩rboles de decisi贸n son modelos interpretables que dividen el espacio de caracter铆sticas en regiones distintas para clasificar o predecir. Son 煤tiles en aplicaciones donde se requiere transparencia y f谩cil interpretaci贸n.
    """)

    # Entrenamiento del modelo de 谩rbol de decisi贸n
    tree_model = DecisionTreeClassifier()
    tree_model.fit(X_train, y_train)
    
    # Realizar predicciones con el modelo
    y_pred = tree_model.predict(X_test)
    
    # Visualizaci贸n del rbol de Decisi贸n
    st.write("Diagrama del rbol de Decisi贸n:")
    from sklearn.tree import plot_tree
    fig, ax = plt.subplots(figsize=(12, 8))
    plot_tree(tree_model, filled=True, feature_names=data.feature_names, class_names=data.target_names, ax=ax)
    st.pyplot(fig)

    # Resultados de la Matriz de Confusi贸n
    st.write("Matriz de Confusi贸n para rbol de Decisi贸n:")
    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots()
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
    st.pyplot(fig)
    
    # Informe de clasificaci贸n para el modelo de rbol de Decisi贸n
    st.write("Informe de clasificaci贸n para rbol de Decisi贸n:")
    st.text(classification_report(y_test, y_pred))


# Footer
st.markdown("---")
st.markdown("Contacto: Alexander Eduardo Rojas Garay")
st.markdown(" Tel茅fono: 7225597963 | 锔 Email: rojasalexander10@gmail.com")
